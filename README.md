
# Researchly

Researchly is envisioned as a Python-based project leveraging the power of LangChain to provide users with concise summaries of research papers. This tool aims to be highly adaptable, offering customizable features such as the desired explanation style (e.g., technical, layperson) and the length of the summary (e.g., short, detailed). Researchly intends to integrate seamlessly with both open-source language models available through platforms like Hugging Face and closed-source models accessible via APIs, offering users flexibility in their choice of language processing power. By combining LangChain's modularity with the diverse capabilities of various language models, Researchly strives to streamline the process of understanding complex research by delivering tailored and accessible summaries.


## Languages and libraries
* Python
* LangChain
* Streamlit
## Key Concepts
* **LangChain**: LangChain is a framework designed to simplify the development of applications powered by large language models (LLMs). It provides a modular and flexible architecture that allows developers to connect various components, such as prompt templates, language models, vector stores, and output parsers, to create sophisticated AI workflows. LangChain aims to abstract away much of the complexity involved in interacting with LLMs, enabling the creation of applications for tasks like question answering, text generation, summarization, and more. Â  
* **Prompt**: Prompt is the input text provided to the model that guides its response. It serves as the initial context and instructions for the model to generate relevant and coherent output. Prompts can range from simple questions or statements to more complex instructions that specify the desired format, style, and content of the model's generation. Crafting effective prompts, often referred to as prompt engineering, is crucial for eliciting the desired behavior and high-quality results from language models.
* **Model**: Model in the realm of artificial intelligence and particularly in the context of language processing, refers to a trained system that has learned patterns and relationships from a large dataset. For language models, this training enables them to understand and generate human-like text. These models encapsulate a vast amount of knowledge and the ability to perform various language-related tasks, such as translation, summarization, and question answering, based on the input they receive.
* **Parser**: Parser, in the context of language model applications, is a component responsible for structuring and extracting specific information from the raw output generated by the language model. Since LLM outputs are often in natural language, a parser transforms this unstructured text into a more usable format, such as structured data (e.g., JSON, lists) or specific data types. This allows downstream applications to easily process and utilize the information produced by the language model.
* **HuggingFace**: Hugging Face is a company and a widely used open-source platform and community for natural language processing (NLP). It provides a vast library of pre-trained models, datasets, and tools that simplify the development and deployment of NLP applications. The Hugging Face Transformers library is particularly popular, offering easy access to thousands of state-of-the-art language models. The platform fosters collaboration and knowledge sharing within the NLP community.
* **Streamlit**: Streamlit is an open-source Python library that makes it incredibly easy to create interactive web applications for machine learning and data science projects. With Streamlit, developers can turn Python scripts into shareable web apps in just a few lines of code, without requiring extensive web development knowledge. This allows for rapid prototyping and the creation of user-friendly interfaces for showcasing and interacting with language model applications.
* **Language Models**: Language Models are a type of artificial intelligence model that is trained to understand and generate human language. These models learn the statistical relationships between words and phrases in a large corpus of text, enabling them to predict the next word in a sequence or generate coherent and contextually relevant text. Language models are the foundation for many natural language processing tasks, including text generation, translation, and question answering.
* **LLMs**: LLMs, which stands for Large Language Models, are advanced language models characterized by their massive size in terms of the number of parameters (the internal variables the model learns during training) and the vast amounts of text data they are trained on. This scale allows LLMs to exhibit emergent abilities, meaning they can perform complex tasks and demonstrate a deeper understanding of language that smaller language models typically cannot. Examples of LLMs include models like GPT-3, LaMDA, and PaLM.

